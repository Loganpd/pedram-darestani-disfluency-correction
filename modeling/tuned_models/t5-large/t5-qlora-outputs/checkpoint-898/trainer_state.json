{
  "best_global_step": 800,
  "best_metric": 0.940773511984264,
  "best_model_checkpoint": "./tuned_models/t5-large/t5-qlora-outputs/checkpoint-500",
  "epoch": 1.0,
  "eval_steps": 100,
  "global_step": 898,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011135857461024499,
      "grad_norm": 2.962634325027466,
      "learning_rate": 1.8e-05,
      "loss": 3.0392,
      "step": 10
    },
    {
      "epoch": 0.022271714922048998,
      "grad_norm": 2.623966693878174,
      "learning_rate": 3.8e-05,
      "loss": 2.8678,
      "step": 20
    },
    {
      "epoch": 0.0334075723830735,
      "grad_norm": 0.8088638186454773,
      "learning_rate": 5.8e-05,
      "loss": 2.8795,
      "step": 30
    },
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 2.180382013320923,
      "learning_rate": 7.800000000000001e-05,
      "loss": 2.7676,
      "step": 40
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 2.993267774581909,
      "learning_rate": 9.8e-05,
      "loss": 2.8111,
      "step": 50
    },
    {
      "epoch": 0.066815144766147,
      "grad_norm": 14.512188911437988,
      "learning_rate": 0.000118,
      "loss": 2.5598,
      "step": 60
    },
    {
      "epoch": 0.0779510022271715,
      "grad_norm": 1.6310137510299683,
      "learning_rate": 0.000138,
      "loss": 1.9955,
      "step": 70
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 8.613585472106934,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.6539,
      "step": 80
    },
    {
      "epoch": 0.10022271714922049,
      "grad_norm": 1.5625979900360107,
      "learning_rate": 0.00017800000000000002,
      "loss": 1.2198,
      "step": 90
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 1.2845544815063477,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.6599,
      "step": 100
    },
    {
      "epoch": 0.111358574610245,
      "eval_bleu": 0.5567869552921036,
      "eval_loss": 0.48207804560661316,
      "eval_meteor": 0.8278681941840556,
      "eval_rouge1": 0.7649410306187862,
      "eval_rouge2": 0.6634785859070332,
      "eval_rougeL": 0.7517288495806356,
      "eval_rougeLsum": 0.7511740777296634,
      "eval_runtime": 203.1527,
      "eval_samples_per_second": 4.922,
      "eval_steps_per_second": 0.615,
      "step": 100
    },
    {
      "epoch": 0.12249443207126949,
      "grad_norm": 1.883522391319275,
      "learning_rate": 0.00019774436090225567,
      "loss": 0.5475,
      "step": 110
    },
    {
      "epoch": 0.133630289532294,
      "grad_norm": 0.4662191569805145,
      "learning_rate": 0.00019523809523809525,
      "loss": 0.5061,
      "step": 120
    },
    {
      "epoch": 0.1447661469933185,
      "grad_norm": 0.944804310798645,
      "learning_rate": 0.00019273182957393485,
      "loss": 0.414,
      "step": 130
    },
    {
      "epoch": 0.155902004454343,
      "grad_norm": 1.2777032852172852,
      "learning_rate": 0.00019022556390977443,
      "loss": 0.3699,
      "step": 140
    },
    {
      "epoch": 0.16703786191536749,
      "grad_norm": 1.066816806793213,
      "learning_rate": 0.00018771929824561406,
      "loss": 0.3453,
      "step": 150
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 1.6932846307754517,
      "learning_rate": 0.00018521303258145364,
      "loss": 0.4032,
      "step": 160
    },
    {
      "epoch": 0.18930957683741648,
      "grad_norm": 0.8306149244308472,
      "learning_rate": 0.00018270676691729324,
      "loss": 0.4866,
      "step": 170
    },
    {
      "epoch": 0.20044543429844097,
      "grad_norm": 0.8826817274093628,
      "learning_rate": 0.00018020050125313285,
      "loss": 0.257,
      "step": 180
    },
    {
      "epoch": 0.21158129175946547,
      "grad_norm": 0.5201349258422852,
      "learning_rate": 0.00017769423558897245,
      "loss": 0.5023,
      "step": 190
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 0.9970283508300781,
      "learning_rate": 0.00017518796992481203,
      "loss": 0.3088,
      "step": 200
    },
    {
      "epoch": 0.22271714922049,
      "eval_bleu": 0.805534451488925,
      "eval_loss": 0.26120424270629883,
      "eval_meteor": 0.9100394427580769,
      "eval_rouge1": 0.9102350022707115,
      "eval_rouge2": 0.8523923959702071,
      "eval_rougeL": 0.8978173322463366,
      "eval_rougeLsum": 0.8976140270082023,
      "eval_runtime": 194.4344,
      "eval_samples_per_second": 5.143,
      "eval_steps_per_second": 0.643,
      "step": 200
    },
    {
      "epoch": 0.23385300668151449,
      "grad_norm": 0.7269123196601868,
      "learning_rate": 0.00017268170426065164,
      "loss": 0.3544,
      "step": 210
    },
    {
      "epoch": 0.24498886414253898,
      "grad_norm": 1.104854702949524,
      "learning_rate": 0.00017017543859649124,
      "loss": 0.3639,
      "step": 220
    },
    {
      "epoch": 0.2561247216035635,
      "grad_norm": 1.2682617902755737,
      "learning_rate": 0.00016766917293233085,
      "loss": 0.4775,
      "step": 230
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.9246366620063782,
      "learning_rate": 0.00016516290726817042,
      "loss": 0.2256,
      "step": 240
    },
    {
      "epoch": 0.27839643652561247,
      "grad_norm": 0.8950859904289246,
      "learning_rate": 0.00016265664160401003,
      "loss": 0.2623,
      "step": 250
    },
    {
      "epoch": 0.289532293986637,
      "grad_norm": 0.7137312293052673,
      "learning_rate": 0.00016015037593984963,
      "loss": 0.2316,
      "step": 260
    },
    {
      "epoch": 0.30066815144766146,
      "grad_norm": 1.068389892578125,
      "learning_rate": 0.00015764411027568924,
      "loss": 0.2702,
      "step": 270
    },
    {
      "epoch": 0.311804008908686,
      "grad_norm": 1.5237393379211426,
      "learning_rate": 0.00015513784461152882,
      "loss": 0.4515,
      "step": 280
    },
    {
      "epoch": 0.32293986636971045,
      "grad_norm": 1.5679609775543213,
      "learning_rate": 0.00015263157894736845,
      "loss": 0.3349,
      "step": 290
    },
    {
      "epoch": 0.33407572383073497,
      "grad_norm": 0.8841897249221802,
      "learning_rate": 0.00015012531328320803,
      "loss": 0.2916,
      "step": 300
    },
    {
      "epoch": 0.33407572383073497,
      "eval_bleu": 0.8472695507983944,
      "eval_loss": 0.22157305479049683,
      "eval_meteor": 0.9322755127206115,
      "eval_rouge1": 0.9329547823708582,
      "eval_rouge2": 0.8851589466632779,
      "eval_rougeL": 0.9226611475270948,
      "eval_rougeLsum": 0.9227762490470142,
      "eval_runtime": 194.5844,
      "eval_samples_per_second": 5.139,
      "eval_steps_per_second": 0.642,
      "step": 300
    },
    {
      "epoch": 0.34521158129175944,
      "grad_norm": 4.36979866027832,
      "learning_rate": 0.00014761904761904763,
      "loss": 0.4184,
      "step": 310
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.9339919686317444,
      "learning_rate": 0.0001451127819548872,
      "loss": 0.3803,
      "step": 320
    },
    {
      "epoch": 0.3674832962138085,
      "grad_norm": 0.8965291976928711,
      "learning_rate": 0.00014260651629072684,
      "loss": 0.3224,
      "step": 330
    },
    {
      "epoch": 0.37861915367483295,
      "grad_norm": 1.0598790645599365,
      "learning_rate": 0.00014010025062656642,
      "loss": 0.3002,
      "step": 340
    },
    {
      "epoch": 0.3897550111358575,
      "grad_norm": 0.9917226433753967,
      "learning_rate": 0.00013759398496240602,
      "loss": 0.2474,
      "step": 350
    },
    {
      "epoch": 0.40089086859688194,
      "grad_norm": 0.43851935863494873,
      "learning_rate": 0.00013508771929824563,
      "loss": 0.2901,
      "step": 360
    },
    {
      "epoch": 0.41202672605790647,
      "grad_norm": 5.074499607086182,
      "learning_rate": 0.00013258145363408523,
      "loss": 0.1989,
      "step": 370
    },
    {
      "epoch": 0.42316258351893093,
      "grad_norm": 0.5449448823928833,
      "learning_rate": 0.0001300751879699248,
      "loss": 0.1906,
      "step": 380
    },
    {
      "epoch": 0.43429844097995546,
      "grad_norm": 1.014164924621582,
      "learning_rate": 0.00012756892230576442,
      "loss": 0.2734,
      "step": 390
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.6732085943222046,
      "learning_rate": 0.00012506265664160402,
      "loss": 0.2701,
      "step": 400
    },
    {
      "epoch": 0.44543429844098,
      "eval_bleu": 0.8634014501577703,
      "eval_loss": 0.20307709276676178,
      "eval_meteor": 0.9407056143487366,
      "eval_rouge1": 0.9406577263094398,
      "eval_rouge2": 0.897511653155807,
      "eval_rougeL": 0.9305291545624548,
      "eval_rougeLsum": 0.930033999912078,
      "eval_runtime": 200.8531,
      "eval_samples_per_second": 4.979,
      "eval_steps_per_second": 0.622,
      "step": 400
    },
    {
      "epoch": 0.45657015590200445,
      "grad_norm": 0.6598249673843384,
      "learning_rate": 0.00012255639097744363,
      "loss": 0.2289,
      "step": 410
    },
    {
      "epoch": 0.46770601336302897,
      "grad_norm": 1.13396418094635,
      "learning_rate": 0.00012005012531328322,
      "loss": 0.2225,
      "step": 420
    },
    {
      "epoch": 0.47884187082405344,
      "grad_norm": 0.8899224996566772,
      "learning_rate": 0.00011754385964912282,
      "loss": 0.29,
      "step": 430
    },
    {
      "epoch": 0.48997772828507796,
      "grad_norm": 0.42892032861709595,
      "learning_rate": 0.00011503759398496242,
      "loss": 0.2384,
      "step": 440
    },
    {
      "epoch": 0.5011135857461024,
      "grad_norm": 1.0434874296188354,
      "learning_rate": 0.00011253132832080202,
      "loss": 0.3154,
      "step": 450
    },
    {
      "epoch": 0.512249443207127,
      "grad_norm": 1.4551748037338257,
      "learning_rate": 0.00011002506265664161,
      "loss": 0.3434,
      "step": 460
    },
    {
      "epoch": 0.5233853006681515,
      "grad_norm": 0.42938417196273804,
      "learning_rate": 0.00010751879699248122,
      "loss": 0.2638,
      "step": 470
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.8049705028533936,
      "learning_rate": 0.00010501253132832081,
      "loss": 0.2063,
      "step": 480
    },
    {
      "epoch": 0.5456570155902004,
      "grad_norm": 0.7843217253684998,
      "learning_rate": 0.00010250626566416041,
      "loss": 0.2233,
      "step": 490
    },
    {
      "epoch": 0.5567928730512249,
      "grad_norm": 0.49146443605422974,
      "learning_rate": 0.0001,
      "loss": 0.2219,
      "step": 500
    },
    {
      "epoch": 0.5567928730512249,
      "eval_bleu": 0.8758263078324152,
      "eval_loss": 0.1945132166147232,
      "eval_meteor": 0.9453498057473193,
      "eval_rouge1": 0.9445887125445813,
      "eval_rouge2": 0.904384887473656,
      "eval_rougeL": 0.9343368745493583,
      "eval_rougeLsum": 0.9340850097224189,
      "eval_runtime": 197.4901,
      "eval_samples_per_second": 5.064,
      "eval_steps_per_second": 0.633,
      "step": 500
    },
    {
      "epoch": 0.5679287305122495,
      "grad_norm": 1.240742564201355,
      "learning_rate": 9.749373433583961e-05,
      "loss": 0.3007,
      "step": 510
    },
    {
      "epoch": 0.579064587973274,
      "grad_norm": 0.4864107370376587,
      "learning_rate": 9.49874686716792e-05,
      "loss": 0.2183,
      "step": 520
    },
    {
      "epoch": 0.5902004454342984,
      "grad_norm": 0.578341007232666,
      "learning_rate": 9.24812030075188e-05,
      "loss": 0.1632,
      "step": 530
    },
    {
      "epoch": 0.6013363028953229,
      "grad_norm": 0.7846951484680176,
      "learning_rate": 8.99749373433584e-05,
      "loss": 0.2511,
      "step": 540
    },
    {
      "epoch": 0.6124721603563474,
      "grad_norm": 1.1904881000518799,
      "learning_rate": 8.7468671679198e-05,
      "loss": 0.391,
      "step": 550
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.6667717695236206,
      "learning_rate": 8.49624060150376e-05,
      "loss": 0.2084,
      "step": 560
    },
    {
      "epoch": 0.6347438752783965,
      "grad_norm": 0.9101772308349609,
      "learning_rate": 8.24561403508772e-05,
      "loss": 0.173,
      "step": 570
    },
    {
      "epoch": 0.6458797327394209,
      "grad_norm": 1.2131198644638062,
      "learning_rate": 7.994987468671679e-05,
      "loss": 0.3171,
      "step": 580
    },
    {
      "epoch": 0.6570155902004454,
      "grad_norm": 0.923954427242279,
      "learning_rate": 7.74436090225564e-05,
      "loss": 0.2057,
      "step": 590
    },
    {
      "epoch": 0.6681514476614699,
      "grad_norm": 0.782665491104126,
      "learning_rate": 7.4937343358396e-05,
      "loss": 0.2391,
      "step": 600
    },
    {
      "epoch": 0.6681514476614699,
      "eval_bleu": 0.8807156476588459,
      "eval_loss": 0.18917331099510193,
      "eval_meteor": 0.946859277954047,
      "eval_rouge1": 0.9478356049772028,
      "eval_rouge2": 0.9107532894895052,
      "eval_rougeL": 0.9389829429907499,
      "eval_rougeLsum": 0.9387239296237994,
      "eval_runtime": 198.1898,
      "eval_samples_per_second": 5.046,
      "eval_steps_per_second": 0.631,
      "step": 600
    },
    {
      "epoch": 0.6792873051224945,
      "grad_norm": 0.42094090580940247,
      "learning_rate": 7.243107769423559e-05,
      "loss": 0.2049,
      "step": 610
    },
    {
      "epoch": 0.6904231625835189,
      "grad_norm": 0.632842481136322,
      "learning_rate": 6.99248120300752e-05,
      "loss": 0.2487,
      "step": 620
    },
    {
      "epoch": 0.7015590200445434,
      "grad_norm": 0.9567087888717651,
      "learning_rate": 6.741854636591479e-05,
      "loss": 0.3413,
      "step": 630
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.44041338562965393,
      "learning_rate": 6.49122807017544e-05,
      "loss": 0.1365,
      "step": 640
    },
    {
      "epoch": 0.7238307349665924,
      "grad_norm": 0.7869279384613037,
      "learning_rate": 6.240601503759398e-05,
      "loss": 0.1693,
      "step": 650
    },
    {
      "epoch": 0.734966592427617,
      "grad_norm": 0.5144494771957397,
      "learning_rate": 5.989974937343359e-05,
      "loss": 0.17,
      "step": 660
    },
    {
      "epoch": 0.7461024498886414,
      "grad_norm": 0.2047288715839386,
      "learning_rate": 5.739348370927319e-05,
      "loss": 0.2099,
      "step": 670
    },
    {
      "epoch": 0.7572383073496659,
      "grad_norm": 1.9386056661605835,
      "learning_rate": 5.4887218045112786e-05,
      "loss": 0.2122,
      "step": 680
    },
    {
      "epoch": 0.7683741648106904,
      "grad_norm": 0.8273969888687134,
      "learning_rate": 5.2380952380952384e-05,
      "loss": 0.2644,
      "step": 690
    },
    {
      "epoch": 0.779510022271715,
      "grad_norm": 0.4986830949783325,
      "learning_rate": 4.987468671679198e-05,
      "loss": 0.2511,
      "step": 700
    },
    {
      "epoch": 0.779510022271715,
      "eval_bleu": 0.8832986139660753,
      "eval_loss": 0.18606577813625336,
      "eval_meteor": 0.9485154292583922,
      "eval_rouge1": 0.9480314965745924,
      "eval_rouge2": 0.9106852545103067,
      "eval_rougeL": 0.9391967859041787,
      "eval_rougeLsum": 0.9388431282599826,
      "eval_runtime": 196.3555,
      "eval_samples_per_second": 5.093,
      "eval_steps_per_second": 0.637,
      "step": 700
    },
    {
      "epoch": 0.7906458797327395,
      "grad_norm": 1.1576427221298218,
      "learning_rate": 4.736842105263158e-05,
      "loss": 0.2488,
      "step": 710
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 1.3106098175048828,
      "learning_rate": 4.486215538847118e-05,
      "loss": 0.1501,
      "step": 720
    },
    {
      "epoch": 0.8129175946547884,
      "grad_norm": 1.8582065105438232,
      "learning_rate": 4.235588972431078e-05,
      "loss": 0.181,
      "step": 730
    },
    {
      "epoch": 0.8240534521158129,
      "grad_norm": 1.037691354751587,
      "learning_rate": 3.9849624060150376e-05,
      "loss": 0.2566,
      "step": 740
    },
    {
      "epoch": 0.8351893095768375,
      "grad_norm": 1.502589225769043,
      "learning_rate": 3.7343358395989974e-05,
      "loss": 0.2225,
      "step": 750
    },
    {
      "epoch": 0.8463251670378619,
      "grad_norm": 0.8669512867927551,
      "learning_rate": 3.483709273182957e-05,
      "loss": 0.2001,
      "step": 760
    },
    {
      "epoch": 0.8574610244988864,
      "grad_norm": 0.5573716163635254,
      "learning_rate": 3.233082706766917e-05,
      "loss": 0.1772,
      "step": 770
    },
    {
      "epoch": 0.8685968819599109,
      "grad_norm": 1.2461235523223877,
      "learning_rate": 2.9824561403508772e-05,
      "loss": 0.1894,
      "step": 780
    },
    {
      "epoch": 0.8797327394209354,
      "grad_norm": 0.6978151202201843,
      "learning_rate": 2.731829573934837e-05,
      "loss": 0.1933,
      "step": 790
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 1.1693062782287598,
      "learning_rate": 2.4812030075187968e-05,
      "loss": 0.3732,
      "step": 800
    },
    {
      "epoch": 0.89086859688196,
      "eval_bleu": 0.8865571015964431,
      "eval_loss": 0.18334487080574036,
      "eval_meteor": 0.9494418888511599,
      "eval_rouge1": 0.9502346203463765,
      "eval_rouge2": 0.9134672109873081,
      "eval_rougeL": 0.941016500009956,
      "eval_rougeLsum": 0.940773511984264,
      "eval_runtime": 196.8459,
      "eval_samples_per_second": 5.08,
      "eval_steps_per_second": 0.635,
      "step": 800
    },
    {
      "epoch": 0.9020044543429844,
      "grad_norm": 0.3471289575099945,
      "learning_rate": 2.230576441102757e-05,
      "loss": 0.1476,
      "step": 810
    },
    {
      "epoch": 0.9131403118040089,
      "grad_norm": 0.9529465436935425,
      "learning_rate": 1.9799498746867168e-05,
      "loss": 0.2149,
      "step": 820
    },
    {
      "epoch": 0.9242761692650334,
      "grad_norm": 0.9262496829032898,
      "learning_rate": 1.7293233082706766e-05,
      "loss": 0.1979,
      "step": 830
    },
    {
      "epoch": 0.9354120267260579,
      "grad_norm": 1.3568156957626343,
      "learning_rate": 1.4786967418546366e-05,
      "loss": 0.221,
      "step": 840
    },
    {
      "epoch": 0.9465478841870824,
      "grad_norm": 1.134716510772705,
      "learning_rate": 1.2280701754385964e-05,
      "loss": 0.3105,
      "step": 850
    },
    {
      "epoch": 0.9576837416481069,
      "grad_norm": 0.4828803241252899,
      "learning_rate": 9.774436090225564e-06,
      "loss": 0.1782,
      "step": 860
    },
    {
      "epoch": 0.9688195991091314,
      "grad_norm": 0.7371702194213867,
      "learning_rate": 7.2681704260651625e-06,
      "loss": 0.2046,
      "step": 870
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.8275513648986816,
      "learning_rate": 4.7619047619047615e-06,
      "loss": 0.215,
      "step": 880
    },
    {
      "epoch": 0.9910913140311804,
      "grad_norm": 0.6793268322944641,
      "learning_rate": 2.255639097744361e-06,
      "loss": 0.2104,
      "step": 890
    }
  ],
  "logging_steps": 10,
  "max_steps": 898,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3900355768221696.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
